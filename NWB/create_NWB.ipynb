{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open namepsace and get exetnsions for multichannel volumetric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pynwb import load_namespaces, get_class\n",
    "from pynwb.file import MultiContainerInterface, NWBContainer\n",
    "import skimage.io as skio\n",
    "from collections.abc import Iterable\n",
    "import numpy as np\n",
    "from pynwb import register_class\n",
    "from hdmf.utils import docval, get_docval, popargs\n",
    "from pynwb.ophys import ImageSeries \n",
    "from pynwb.core import NWBDataInterface\n",
    "from hdmf.common import DynamicTable\n",
    "from hdmf.utils import docval, popargs, get_docval, get_data_shape, popargs_to_dict\n",
    "from pynwb.file import Device\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pynwb import NWBFile, TimeSeries, NWBHDF5IO\n",
    "from pynwb.epoch import TimeIntervals\n",
    "from pynwb.file import Subject\n",
    "from pynwb.behavior import SpatialSeries, Position\n",
    "from pynwb.image import ImageSeries\n",
    "from pynwb.ophys import OnePhotonSeries, OpticalChannel, ImageSegmentation, Fluorescence, CorrectedImageStack, MotionCorrection, RoiResponseSeries\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from datetime import datetime, timedelta\n",
    "import tifffile\n",
    "from MultiChannelVol import CElegansSubject, OpticalChannelReferences, OpticalChannelPlus, ImagingVolume, VolumeSegmentation, MultiChannelVolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.path.join('/Users', 'danielsprague', 'FOCO_lab', 'data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating NWB file for NeuroPAL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_file(description, identifier, start_date_time, lab, institution, pubs):\n",
    "\n",
    "    nwbfile = NWBFile(\n",
    "        session_description = description,\n",
    "        identifier = identifier,\n",
    "        session_start_time = start_date_time,\n",
    "        lab = lab,\n",
    "        institution = institution,\n",
    "        related_publications = pubs\n",
    "    )\n",
    "\n",
    "    return nwbfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_im_vol(device, channels, location=\"head\", grid_spacing=[0.3208, 0.3208, 0.75], grid_spacing_unit =\"micrometers\", origin_coords=[0,0,0], origin_coords_unit=\"micrometers\", reference_frame=\"Worm head, left=anterior, bottom=ventral\"):\n",
    "    \n",
    "    # channels should be ordered list of tuples (name, description)\n",
    "\n",
    "    OptChannels = []\n",
    "    OptChanRefData = []\n",
    "    for name, wave in channels:\n",
    "        excite = float(wave.split('-')[0])\n",
    "        emiss_mid = float(wave.split('-')[1])\n",
    "        emiss_range = float(wave.split('-')[2][:-1])\n",
    "        OptChan = OpticalChannelPlus(\n",
    "            name = name,\n",
    "            description = wave,\n",
    "            excitation_lambda = excite,\n",
    "            excitation_range = [excite, excite],\n",
    "            emission_range = [emiss_mid-emiss_range/2, emiss_mid+emiss_range/2],\n",
    "            emission_lambda = emiss_mid\n",
    "        )\n",
    "\n",
    "        OptChannels.append(OptChan)\n",
    "        OptChanRefData.append(wave)\n",
    "\n",
    "    OpticalChannelRefs = OpticalChannelReferences(\n",
    "        name = 'OpticalChannelRefs',\n",
    "        data = OptChanRefData\n",
    "    )\n",
    "\n",
    "    imaging_vol = ImagingVolume(\n",
    "        name= 'ImagingVolume',\n",
    "        optical_channel_plus = OptChannels,\n",
    "        Order_optical_channels = OpticalChannelRefs,\n",
    "        description = 'NeuroPAL image of C elegan brain',\n",
    "        device = device,\n",
    "        location = location,\n",
    "        grid_spacing = grid_spacing,\n",
    "        grid_spacing_unit = grid_spacing_unit,\n",
    "        origin_coords = origin_coords,\n",
    "        origin_coords_unit = origin_coords_unit,\n",
    "        reference_frame = reference_frame\n",
    "    )\n",
    "\n",
    "    return imaging_vol, OpticalChannelRefs, OptChannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vol_seg(imaging_vol, blobs):\n",
    "\n",
    "    vs = VolumeSegmentation(\n",
    "        name = 'VolumeSegmentation',\n",
    "        description = 'Neuron centers for multichannel volumetric image',\n",
    "        imaging_volume = imaging_vol\n",
    "    )\n",
    "\n",
    "    csv = pd.read_csv(blobs)\n",
    "\n",
    "    voxel_mask = []\n",
    "\n",
    "    for i, row in csv.iterrows():\n",
    "        x = row['X']\n",
    "        y = row['Y']\n",
    "        z = row['Z']\n",
    "        ID = row['ID']\n",
    "\n",
    "        voxel_mask.append([np.uint(x),np.uint(y),np.uint(z),1,str(ID)])\n",
    "\n",
    "    vs.add_roi(voxel_mask=voxel_mask)\n",
    "\n",
    "    return vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image(data, name, description, imaging_volume, resolution=[0.3208, 0.3208, 0.75], RGBW_channels=[0,1,2,3]):\n",
    "\n",
    "    image = MultiChannelVolume(\n",
    "        name = name,\n",
    "        resolution = resolution,\n",
    "        description = description,\n",
    "        RGBW_channels = RGBW_channels,\n",
    "        data = data,\n",
    "        imaging_volume = imaging_volume\n",
    "    )\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create NWB file from tif file of raw image, neuroPAL software created mat file and csv files of blob locations\n",
    "'''\n",
    "\n",
    "def create_file_FOCO(folder, reference_frame):\n",
    "\n",
    "    worm = folder.split('/')[1]\n",
    "\n",
    "    path = datapath+'/'+folder\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        if file[-4:] =='.tif':\n",
    "            imfile = path + '/'+file\n",
    "\n",
    "        elif file[-4:] == '.mat' and file[-6:]!= 'ID.mat':\n",
    "            matfile = path + '/'+file\n",
    "\n",
    "        elif file == 'blobs.csv':\n",
    "            blobs = path +'/'+file\n",
    "\n",
    "    data = np.transpose(skio.imread(imfile), (1,0,2,3)) #data should be XYZC\n",
    "    #data = data.astype('uint16')\n",
    "    mat = sio.loadmat(matfile)\n",
    "\n",
    "    scale = np.asarray(mat['info']['scale'][0][0]).flatten()\n",
    "    prefs = np.asarray(mat['prefs']['RGBW'][0][0]).flatten()-1 #subtract 1 to adjust for matlab indexing from 1\n",
    "    \n",
    "    dt = worm.split('-')\n",
    "    session_start = datetime(int(dt[0]),int(dt[1]),int(dt[2]), tzinfo=tz.gettz(\"US/Pacific\"))\n",
    "    \n",
    "    nwbfile = gen_file('Worm head', worm, session_start, 'Kato lab', 'UCSF', \"\")\n",
    "\n",
    "    nwbfile.subject = CElegansSubject(\n",
    "    subject_id = worm,\n",
    "    #age = \"T2H30M\",\n",
    "    #growth_stage_time = pd.Timedelta(hours=2, minutes=30).isoformat(),\n",
    "    date_of_birth = session_start, #currently just using the session start time to bypass the requirement for date of birth\n",
    "    growth_stage = 'YA',\n",
    "    cultivation_temp = 20.,\n",
    "    description = dt[3]+'-'+dt[4],\n",
    "    species  =  \"http://purl.obolibrary.org/obo/NCBITaxon_6239\",\n",
    "    sex = \"F\", #currently just using O for other until support added for other gender specifications\n",
    "    strain = \"OH16230\"\n",
    "    )\n",
    "\n",
    "    device = nwbfile.create_device(\n",
    "    name = \"Microscope\",\n",
    "    description = \"One-photon microscope Weill\",\n",
    "    manufacturer = \"Leica\"\n",
    "    )\n",
    "\n",
    "    channels = [(\"mNeptune 2.5\", \"561-700-75m\"), (\"Tag RFP-T\", \"561-605-70m\"), (\"CyOFP1\", \"488-605-70m\"), (\"GFP-GCaMP\", \"488-525-50m\"), (\"mTagBFP2\", \"405-460-50m\"), (\"mNeptune 2.5 - high excite\", \"639-700-75m\")]\n",
    "    \n",
    "    ImagingVol, OptChannelRefs, OpticalChannelPlus = create_im_vol(device, channels, location= \"head\", grid_spacing= scale, reference_frame=reference_frame)\n",
    "\n",
    "    vs = create_vol_seg(ImagingVol, blobs)\n",
    "\n",
    "    image= create_image(data, 'NeuroPALImageRaw', worm, ImagingVol, resolution=scale, RGBW_channels=[0,2,4,1])\n",
    "\n",
    "    nwbfile.add_acquisition(image)\n",
    "\n",
    "    neuroPAL_module = nwbfile.create_processing_module(\n",
    "        name = 'NeuroPAL',\n",
    "        description = 'neuroPAL image data and metadata',\n",
    "    )    \n",
    "\n",
    "    processed_im_module = nwbfile.create_processing_module(\n",
    "        name = 'ProcessedImage',\n",
    "        description = 'Pre-processed image. Currently median filtered and histogram matched to original neuroPAL images.'\n",
    "    )\n",
    "\n",
    "    proc_imfile = datapath + '/NP_FOCO_hist_med/'+worm+'/hist_med_image.tif'\n",
    "\n",
    "    proc_data = np.transpose(skio.imread(proc_imfile), (0,3,1,2))\n",
    "    #proc_data = proc_data.astype('uint16')\n",
    "\n",
    "    proc_image = create_image(proc_data, 'Hist_match_med_filt', worm, ImagingVol, resolution=scale, RGBW_channels=[0,1,2,3])\n",
    "\n",
    "    neuroPAL_module.add(vs)\n",
    "    neuroPAL_module.add(ImagingVol)\n",
    "    neuroPAL_module.add(OptChannelRefs)\n",
    "    neuroPAL_module.add(OpticalChannelPlus)\n",
    "\n",
    "    processed_im_module.add(proc_image)\n",
    "\n",
    "    io = NWBHDF5IO(datapath+'/nwb/'+worm+'.nwb', mode='w')\n",
    "    io.write(nwbfile)\n",
    "    io.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielsprague/anaconda3/envs/eats-test/lib/python3.8/site-packages/hdmf/build/objectmapper.py:260: DtypeConversionWarning: Spec 'ImagingVolume/origin_coords': Value with data type int64 is being converted to data type float64 (min specification: float32).\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n",
      "/Users/danielsprague/anaconda3/envs/eats-test/lib/python3.8/site-packages/hdmf/build/objectmapper.py:260: DtypeConversionWarning: Spec 'ImagingVolume/origin_coords': Value with data type int64 is being converted to data type float64 (min specification: float32).\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n",
      "/Users/danielsprague/anaconda3/envs/eats-test/lib/python3.8/site-packages/hdmf/build/objectmapper.py:260: DtypeConversionWarning: Spec 'ImagingVolume/origin_coords': Value with data type int64 is being converted to data type float64 (min specification: float32).\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n",
      "/Users/danielsprague/anaconda3/envs/eats-test/lib/python3.8/site-packages/hdmf/build/objectmapper.py:260: DtypeConversionWarning: Spec 'ImagingVolume/origin_coords': Value with data type int64 is being converted to data type float64 (min specification: float32).\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n",
      "/Users/danielsprague/anaconda3/envs/eats-test/lib/python3.8/site-packages/hdmf/build/objectmapper.py:260: DtypeConversionWarning: Spec 'ImagingVolume/origin_coords': Value with data type int64 is being converted to data type float64 (min specification: float32).\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n",
      "/Users/danielsprague/anaconda3/envs/eats-test/lib/python3.8/site-packages/hdmf/build/objectmapper.py:260: DtypeConversionWarning: Spec 'ImagingVolume/origin_coords': Value with data type int64 is being converted to data type float64 (min specification: float32).\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n",
      "/Users/danielsprague/anaconda3/envs/eats-test/lib/python3.8/site-packages/hdmf/build/objectmapper.py:260: DtypeConversionWarning: Spec 'ImagingVolume/origin_coords': Value with data type int64 is being converted to data type float64 (min specification: float32).\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n",
      "/Users/danielsprague/anaconda3/envs/eats-test/lib/python3.8/site-packages/hdmf/build/objectmapper.py:260: DtypeConversionWarning: Spec 'ImagingVolume/origin_coords': Value with data type int64 is being converted to data type float64 (min specification: float32).\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n",
      "/Users/danielsprague/anaconda3/envs/eats-test/lib/python3.8/site-packages/hdmf/build/objectmapper.py:260: DtypeConversionWarning: Spec 'ImagingVolume/origin_coords': Value with data type int64 is being converted to data type float64 (min specification: float32).\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n",
      "/Users/danielsprague/anaconda3/envs/eats-test/lib/python3.8/site-packages/hdmf/build/objectmapper.py:260: DtypeConversionWarning: Spec 'ImagingVolume/origin_coords': Value with data type int64 is being converted to data type float64 (min specification: float32).\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "create_file_FOCO('NP_FOCO_cropped/2021-12-03-w00-NP1', reference_frame = 'origin = anterior, dorsal, left')\n",
    "create_file_FOCO('NP_FOCO_cropped/2022-01-22-w04-NP1', reference_frame = 'origin = posterior, dorsal, left')\n",
    "create_file_FOCO('NP_FOCO_cropped/2022-02-11-w03-NP1', reference_frame = 'origin = posterior, dorsal, left')\n",
    "create_file_FOCO('NP_FOCO_cropped/2022-02-12-w00-NP1', reference_frame = 'origin = posterior, ventral, right')\n",
    "create_file_FOCO('NP_FOCO_cropped/2022-02-12-w01-NP1', reference_frame = 'origin = posterior, ventral, right')\n",
    "create_file_FOCO('NP_FOCO_cropped/2022-02-22-w04-NP1', reference_frame = 'origin = anterior, ventral left; slightly rotated')\n",
    "create_file_FOCO('NP_FOCO_cropped/2022-03-05-w00-NP1', reference_frame = 'origin = posterior, ventral, right')\n",
    "create_file_FOCO('NP_FOCO_cropped/2022-04-01-w00-NP1', reference_frame = 'origin = anterior, dorsal, left')\n",
    "create_file_FOCO('NP_FOCO_cropped/2022-04-26-w00-NP1', reference_frame = 'origin = posterior, dorsal, left; slightly rotated')\n",
    "create_file_FOCO('NP_FOCO_cropped/2022-04-26-w01-NP1', reference_frame = 'origin = posterior, ventral, right')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read NWB files and recreate relevant files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with NWBHDF5IO(datapath+\"/nwb/2022-02-12-w01-NP1.nwb\", mode='r', load_namespaces=True) as io:\n",
    "    read_nwbfile = io.read()\n",
    "    subject = read_nwbfile.subject #get the metadata about the experiment subject\n",
    "    image = read_nwbfile.acquisition['NeuroPALImageRaw'].data[:] #get the neuroPAL image as a np array\n",
    "    resolution = read_nwbfile.acquisition['NeuroPALImageRaw'].resolution[:] #get the resolution of the image in um/pixels\n",
    "    channels = read_nwbfile.acquisition['NeuroPALImageRaw'].RGBW_channels[:] #get which channels of the image correspond to which RGBW pseudocolors\n",
    "    seg = read_nwbfile.processing['NeuroPAL']['VolumeSegmentation'].voxel_mask[:] #get the locations of neuron centers\n",
    "    im_vol = read_nwbfile.processing['NeuroPAL']['ImagingVolume'] #get the metadata associated with the imaging acquisition\n",
    "    optchans = read_nwbfile.processing['NeuroPAL']['ImagingVolume'].optical_channel_plus[:] #get information about all of the optical channels used in acquisition\n",
    "    chan_refs = read_nwbfile.processing['NeuroPAL']['OpticalChannelRefs'].data[:] #get the order of the optical channels in the image\n",
    "    proc_image = read_nwbfile.processing['ProcessedImage']['Hist_match_med_filt'].data[:] #get the pre-processed image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Recreate blobs.csv from vol_seg\n",
    "'''\n",
    "\n",
    "blobs = pd.DataFrame.from_records(seg, columns=['X', 'Y','Z','weight', 'ID'])\n",
    "blobs = blobs.drop(['weight'], axis=1)\n",
    "blobs = blobs.replace('nan', '', regex=True)\n",
    "blobs.to_csv(datapath+'/nwb/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 6, 240, 1000)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Recreate original image from acquisition raw image\n",
    "'''\n",
    "print(image.shape)\n",
    "\n",
    "#im = np.transpose(image,(2,3,1,0)) #have to flip some of the axes to align with how FIJI reads tiff images\n",
    "#image = image.astype('uint16')\n",
    "#print(im.dtype)\n",
    "#print(im.shape)\n",
    "\n",
    "tifffile.imwrite(datapath + '/nwb/test.tif', image, imagej = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 4, 240, 1000)\n",
      "uint16\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "'''\n",
    "Recreate histogram matched image from processed data\n",
    "'''\n",
    "\n",
    "print(proc_image.shape)\n",
    "\n",
    "#im = np.transpose(proc_image, (3,0,2,1)) #have to flip some of the axes to align with how FIJI reads tiff images\n",
    "#proc_image = proc_image.astype('uint16')\n",
    "print(proc_image.dtype)\n",
    "\n",
    "tifffile.imwrite(datapath + '/nwb/test_proc.tif', proc_image, imagej = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eats-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
